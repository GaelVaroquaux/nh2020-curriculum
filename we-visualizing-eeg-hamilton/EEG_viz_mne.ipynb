{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing invasive and non-invasive EEG data\n",
    "\n",
    "[Liberty Hamilton, PhD](https://csd.utexas.edu/research/hamilton-lab)\n",
    "Assistant Professor, University of Texas at Austin\n",
    "Department of Speech, Language, and Hearing Sciences\n",
    "and Department of Neurology, Dell Medical School \n",
    "\n",
    "Welcome! In this notebook we will be discussing how to look at time series electrophysiological ðŸ§  data that is recorded noninvasively at the scalp (scalp electroencephalography or EEG), or invasively in patients who are undergoing surgical treatment for epilepsy (sometimes called intracranial EEG or iEEG, also called stereo EEG/sEEG, or electrocorticography/ECoG). \n",
    "\n",
    "### Python libraries you will be using in this tutorial:\n",
    "* MNE-python\n",
    "* matplotlib\n",
    "* numpy\n",
    "\n",
    "![MNE-python logo](https://mne.tools/stable/_static/mne_logo.png)\n",
    "MNE-python is open source python software for exploring and analyzing human neurophysiological data (EEG/MEG/iEEG).\n",
    "\n",
    "### What you will learn to do \n",
    "* Load some sample EEG data\n",
    "* Load some sample intracranial EEG data\n",
    "* Plot the raw EEG data/iEEG data\n",
    "* Plot the power spectrum of your data\n",
    "* Epoch data according to specific task conditions (sentences)\n",
    "* Plot all epochs and averaged evoked activity\n",
    "* Plot average evoked activity in response to specific task conditions (ERPs)\n",
    "    * Plot by channel as well as averaging across channels\n",
    "* Plot EEG activity at specific time points on the scalp (topomaps)\n",
    "* Customize your plots\n",
    "\n",
    "### Other Resources:\n",
    "* [MNE-python tutorials](https://mne.tools/stable/auto_tutorials/index.html) -- This has many additional resources above and beyond that also include how to preprocess your data, remove artifacts, and more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"basics1\"></a>\n",
    "# 1. The basics: loading in your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib==3.2\n",
    "\n",
    "import mne # This is the mne library\n",
    "import numpy as np # This gives us the power of numpy, which is just generally useful for array manipulation\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "datasets = {'ecog': '/home/jovyan/data/we_eeg_viz_data/ecog/sub-S0006/S0006_ecog_hg.fif',\n",
    "            'eeg': '/home/jovyan/data/we_eeg_viz_data/eeg/sub-MT0002/MT0002-eeg.fif'}\n",
    "event_files = {'ecog': '/home/jovyan/data/we_eeg_viz_data/ecog/sub-S0006/S0006_eve.txt',\n",
    "               'eeg': '/home/jovyan/data/we_eeg_viz_data/eeg/sub-MT0002/MT0002_eve.txt'}\n",
    "stim_file = '/home/jovyan/data/we_eeg_viz_data/stimulus_list.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some information about the stimuli (here, the names of the sound files that were played)\n",
    "ev_names=np.genfromtxt(stim_file, skip_header=1, delimiter=',',dtype=np.str, usecols=[1],encoding='utf-8')\n",
    "ev_nums=np.genfromtxt(stim_file, skip_header=1, delimiter=',',dtype=np.int, usecols=[0], encoding='utf-8')\n",
    "event_id = dict()\n",
    "for i, ev_name in enumerate(ev_names):\n",
    "    event_id[ev_name] = ev_nums[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Choose which dataset to look at (start with EEG)\n",
    "\n",
    "For the purposes of this tutorial, we'll be looking at some scalp EEG and intracranial EEG datasets from my lab.  Participants provided written informed consent for participation in our research. These data were collected from two distinct participants listening to sentences from the [TIMIT acoustic-phonetic corpus](https://catalog.ldc.upenn.edu/LDC93S1). This is a database of English sentences spoken by multiple talkers from throughout the United States, and has been used in speech recognition research, neuroscience research, and more!\n",
    "\n",
    "The list of stimuli is in the `stimulus_list.csv` file. Each stimulus starts with either a \"f\" or a \"m\" to indicate a female or male talker. The rest of the alphanumeric string has to do with other characteristics of the talkers that we won't go into here. The stimulus timings have been provided for you in the event files (ending with the suffix `_eve.txt`. We'll talk about those more later. \n",
    "\n",
    "### EEG Data\n",
    "The EEG data was recorded with a 64-channel [BrainVision ActiCHamp](https://www.brainproducts.com/productdetails.php?id=74) system. These data are part of an ongoing project in our lab and are unpublished. You can find similar (larger) datasets from [Broderick et al.](https://datadryad.org/stash/dataset/doi:10.5061/dryad.070jc), or Bradley Voytek's lab has a list of [Open Electrophysiology datasets](https://github.com/openlists/ElectrophysiologyData).\n",
    "\n",
    "### The ECoG Data\n",
    "The ECoG data was recorded from 106 electrodes across multiple regions of the brain while our participant listened to TIMIT sentences. This is a smaller subset of sentences than the EEG dataset and so is a bit faster to load. The areas we recorded from are labeled according to a clinical montage. For iEEG and ECoG datasets, these names are rarely standardized, so it can be hard to know exactly what is what without additional information. Here, each channel is named according to the general location of the electrode probe to which it belongs.\n",
    "\n",
    "| Device | General location  |\n",
    "|---|---|\n",
    "| RAST   | Right anterior superior temporal  |\n",
    "| RMST   | Right middle superior temporal |\n",
    "| RPST   | Right posterior superior temporal |\n",
    "| RPPST  | Right posterior parietal/superior temporal |\n",
    "| RAIF   | Right anterior insula |\n",
    "| RPI    | Right posterior insula  |\n",
    "| ROF    | Right orbitofrontal  |\n",
    "| RAC    | Right anterior cingulate  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'eeg' # Can choose from 'eeg' or 'ecog'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Load the data\n",
    "\n",
    "This next command loads the data from our fif file of interest. The `preload=True` flag means that the data will be loaded (necessary for some operations). If `preload=False`, you can still perform some aspects of this tutorial, and this is a great option if you have a large dataset and would like to look at some of the header information and metadata before you start to analyze it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_fif(datasets[data_type], preload=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of useful information in the info structure. For example, we can get the sampling frequency (`raw.info['sfreq']`), the channel names (`raw.info['ch_names']`), the channel types and locations (in `raw.info['chs']`), and whether any filtering operations have been performed already (`raw.info['highpass']` and `raw.info['lowpass']` show the cut-offs for the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_freq = raw.info['sfreq'] \n",
    "nchans = raw.info['nchan']\n",
    "\n",
    "print('The sampling frequency of our data is %d'%(sampling_freq))\n",
    "print('Here is our list of %d channels: '%nchans)\n",
    "print(raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eeg_colors = {'eeg': 'k', 'eog': 'steelblue'}\n",
    "fig = raw.plot(show=False, color=eeg_colors, scalings='auto');\n",
    "fig.set_figwidth(8)\n",
    "fig.set_figheight(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plots2\"></a>\n",
    "# 2. Let's make some plots!\n",
    "\n",
    "MNE-python makes creating some plots *super easy*, which is great for data quality checking, exploration, and eventually manuscript figure generation. For example, one might wish to plot the power spectral density (PSD), which \n",
    "\n",
    "## 2.2. Power spectral density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_psd();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Sensor positions (for EEG)\n",
    "\n",
    "For EEG, MNE-python also has convenient functions for showing the location of the sensors used. Here, we have a 64-channel montage. You can also use this information to help interpret some of your plots if you're plotting a single channel or a group of channels.\n",
    "\n",
    "For ECoG, we will not be plotting sensors in this way. If you would like read more about that process, please see [this tutorial](https://mne.tools/stable/auto_tutorials/misc/plot_ecog.html).  You can also check out [Noah Benson's session](https://neurohackademy.org/course/introduction-to-the-geometry-and-structure-of-the-human-brain/) (happening in parallel with this tutorial!) for plotting 3D brains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if data_type == 'eeg':\n",
    "    raw.plot_sensors(kind='topomap',show_names=True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, awesome! So now we know where the sensors are, how densely they tile the space, and what their names are. *Knowledge = Power!*\n",
    "\n",
    "So what if we wanted to look at the power spectral density plot we saw above by channel? We can use `plot_psd_topo` for that! There are also customizable options for playing with the colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'eeg':\n",
    "    raw.plot_psd_topo(fig_facecolor='w', axis_facecolor='w', color='k');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this one works for both EEG and ECoG. Here we are looking at the power spectral density plot again, but taking the average across trials and showing +/- 1 standard deviation from the mean across channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_psd(area_mode='std', average=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot these same figures using a narrower frequency range, and looking at a smaller set of channels using `picks`. For `plot_psd` and other functions, `picks` is a list of integer indices corresponding to your channels of interest. You can choose these by their number, or you can use the convenient `mne.pick_channels` function to choose them by name. For example, in EEG, we often see strong responses to auditory stimuli at the top of the head, so here we will restrict our EEG channels to a few at the top of the head at the midline. For ECoG, we are more likely to see responses to auditory stimuli in temporal lobe electrodes (potentially RPPST, RPST, RMST, RAST), so we'll try those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'eeg':\n",
    "    picks = mne.pick_channels(raw.ch_names, include=['Pz','CPz','Cz','FCz','Fz','C1','C2','FC1','FC2','CP1','CP2'])\n",
    "elif data_type == 'ecog':\n",
    "    picks = mne.pick_channels(raw.ch_names, include=['RPPST9','RPPST10','RPPST11'])\n",
    "\n",
    "raw.plot_psd(picks = picks, fmin=1, fmax=raw.info['sfreq']/2, xscale='log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting responses to events\n",
    "\n",
    "Ok, so this is all well and good. We can plot our raw data, the power spectrum, and the locations of the sensors. But what if we care about responses to the stimuli we described above? What if we want to look at responses to specific sentences, or the average response across all sentences, or something else? How can we determine which EEG sensors or ECoG electrodes respond to the speech stimuli?\n",
    "\n",
    "Enter.... *Epoching!*  MNE-python gives you a very convenient way of rearranging your data according to events of interest. These can actually even be found automatically from a stimulus channel, if you have one (using [`mne.find_events`](https://mne.tools/stable/generated/mne.find_events.html)), which we won't use here because we already have the timings from another procedure. You can also find other types of epochs, like those based on EMG or [eye movements (EOG)](https://mne.tools/stable/generated/mne.preprocessing.find_eog_events.html). \n",
    "\n",
    "Here, we will load our event files (ending with `_eve.txt`). These contain information about the start sample, stop sample, and event ID for each stimulus. Each row in the file is one stimulus. The timings are in samples rather than in seconds, so if you are creating these on your own, pay attention to your sampling rate (in `raw.info['sfreq']`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some events. The format of these is start sample, end sample, and event ID.\n",
    "events = mne.read_events(event_files[data_type])\n",
    "print(events)\n",
    "\n",
    "num_events = len(events)\n",
    "unique_stimuli = np.unique(np.array(events)[:,2])\n",
    "num_unique = len(unique_stimuli)\n",
    "print('There are %d total events, corresponding to %d unique stimuli'%(num_events, num_unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epochs\n",
    "\n",
    "Great. So now that we have the events, we will \"epoch\" our data, which basically uses these timings to split up our data into trials of a given length. We will also set some parameters for data rejection to get rid of noisy trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some rejection criteria. This will be based on the peak-to-peak\n",
    "# amplitude of your data.\n",
    "\n",
    "if data_type=='eeg':\n",
    "    reject = {'eeg': 60e-6} # Higher than peak to peak amplitude of 60 ÂµV will be rejected\n",
    "    scalings = None\n",
    "    units = None\n",
    "elif data_type=='ecog':\n",
    "    reject = {'ecog': 10} # Higher than Z-score of 10 will be rejected\n",
    "    scalings = {'ecog': 1} # Don't rescale these as if they should be in ÂµV\n",
    "    units = {'ecog': 'Z-score'}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmin = -0.2\n",
    "tmax = 1.0\n",
    "epochs = mne.Epochs(raw, events, tmin=tmin, tmax=tmax, baseline=(None, 0), reject=reject, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what's in this epochs data structure? If we look at it, we can see that we have an entry for each event ID, and we can see how many times that stimulus was played. You can also see whether baseline correction was done and for what time period, and whether any data was rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you could decide at this point that you just want to work with the data directly as a numpy array. Luckily, that's super easy to do! We can just call `get_data()` on our epochs data structure, and this will output a matrix of `[events x channels x time points]`. If you do not limit the channel type, you will get all of them (including any EOG, stimulus channels, or other non-EEG/ECoG channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_data = epochs.get_data()\n",
    "print(ep_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Epoched data\n",
    "\n",
    "Ok... so we are getting ahead of ourselves. MNE-python provides a lot of ways to plot our data so that we don't have to deal with writing functions to do this ourselves! For example, if we'd like to plot the EEG/ECoG for all of the single trials we just loaded, along with an average across all of these trials (and channels of interest), we can do that easily with `epochs.plot_image()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.plot_image(combine='mean', scalings=scalings, units=units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can choose specific channels to look at instead of looking at all of them at once. For which method do you think this would make the most difference? Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'eeg':\n",
    "    picks = mne.pick_channels(raw.ch_names, include=['Fz','FCz','Cz','CPz','Pz'])\n",
    "elif data_type == 'ecog':\n",
    "    picks = mne.pick_channels(raw.ch_names, include=['RPPST9','RPPST10','RPPST11'])\n",
    "    \n",
    "epochs.plot_image(picks = picks, combine='mean', scalings=scalings, units=units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also sort the trials, if we would like. This can be very convenient if you have reaction times or some other portion of the trial where reordering would make sense. Here, we'll just pick a channel and order by the mean activity within each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'eeg':\n",
    "    picks = mne.pick_channels(raw.ch_names, include=['CP6'])\n",
    "elif data_type == 'ecog':\n",
    "    picks = mne.pick_channels(raw.ch_names, include=['RPPST2'])\n",
    "\n",
    "# Get the data as a numpy array\n",
    "eps_data = epochs.get_data()\n",
    "\n",
    "# Sort the data \n",
    "new_order = eps_data[:,picks[0],:].mean(1).argsort(0)\n",
    "\n",
    "epochs.plot_image(picks=picks, order=new_order, scalings=scalings, units=units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other ways to view epoched data\n",
    "\n",
    "For EEG, another way to view these epochs by trial is using the scalp topography information. This allows us to quickly assess differences across the scalp in response to the stimuli. What do you notice about the responses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'eeg':\n",
    "    epochs.plot_topo_image(vmin=-30, vmax=30, fig_facecolor='w',font_color='k');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing epochs of different trial types\n",
    "\n",
    "So far we have just shown averages of activity across many different sentences. However, as mentioned above, the sentences come from multiple male and female talkers. So -- one quick split we could try is just to compare the responses to female vs. male talkers. This is relatively simple with the TIMIT stimuli because their file name starts with \"f\" or \"m\" to indicate this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make lists of the event ID numbers corresponding to \"f\" and \"m\" sentences\n",
    "f_evs = []\n",
    "m_evs = []\n",
    "for k in event_id.keys():\n",
    "    if k[0] == 'f':\n",
    "        f_evs.append(event_id[k])\n",
    "    elif k[0] == 'm':\n",
    "        m_evs.append(event_id[k])\n",
    "\n",
    "print(unique_stimuli)\n",
    "f_evs_new = [v for v in f_evs if v in unique_stimuli]\n",
    "m_evs_new = [v for v in m_evs if v in unique_stimuli]\n",
    "\n",
    "# Epoch the data separately for \"f\" and \"m\" epochs\n",
    "f_epochs = mne.Epochs(raw, events, event_id=f_evs_new, tmin=tmin, tmax=tmax, reject=reject)\n",
    "m_epochs = mne.Epochs(raw, events, event_id=m_evs_new, tmin=tmin, tmax=tmax, reject=reject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the epochs just as we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_epochs.plot_image(combine='mean', show=False, scalings=scalings, units=units)\n",
    "m_epochs.plot_image(combine='mean', show=False, scalings=scalings, units=units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! So now we have a separate plot for the \"f\" and \"m\" talkers. However, it's not super convenient to compare the traces this way... we kind of want them on the same axis. MNE easily allows us to do this too! Instead of using the epochs, we can create `evoked` data structures, which are averaged epochs. You can [read more about evoked data structures here](https://mne.tools/dev/auto_tutorials/evoked/plot_10_evoked_overview.html).\n",
    "\n",
    "## Compare evoked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evokeds = {'female': f_epochs.average(), 'male': m_epochs.average()}\n",
    "mne.viz.plot_compare_evokeds(evokeds, show_sensors='upper right',picks=picks);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we actually want errorbars on this plot, we need to do this a bit differently. We can use the `iter_evoked()` method on our epochs structures to create a dictionary of conditions for which we will plot our comparisons with `plot_compare_evokeds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evokeds = {'f':list(f_epochs.iter_evoked()), 'm':list(m_epochs.iter_evoked())}\n",
    "mne.viz.plot_compare_evokeds(evokeds, picks=picks);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting scalp topography\n",
    "\n",
    "For EEG, another common plot you may see is a topographic map showing activity (or other data like p-values, or differences between conditions). In this example, we'll show the activity at -0.2, 0, 0.1, 0.2, 0.3, and 1 second. You can also of course choose just one time to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'eeg':\n",
    "    times=[tmin, 0, 0.1, 0.2, 0.3, tmax]\n",
    "    epochs.average().plot_topomap(times, ch_type='eeg', cmap='PRGn', res=32,\n",
    "                    outlines='skirt', time_unit='s');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot arbitrary data using `mne.viz.plot_topomap`, and passing in a vector of data matching the number of EEG channels, and `raw.info` to give specifics on those channel locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'eeg':\n",
    "    chans = mne.pick_types(raw.info, eeg=True)\n",
    "    data = np.random.randn(len(chans),)\n",
    "    plt.figure()\n",
    "    mne.viz.plot_topomap(data, raw.info, show=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even animate these topo maps! This won't work well in jupyterhub, but feel free to try on your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'eeg':\n",
    "    fig,anim=epochs.average().animate_topomap(blit=False, times=np.linspace(tmin, tmax, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few more fancy EEG plots\n",
    "\n",
    "If we want to get especially fancy, we can also use `plot_joint` with our evoked data (or averaged epoched data, as shown below). This allows us to combine the ERPs for individual channels with topographic maps at time points that we specify. Pretty awesome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'eeg':\n",
    "    epochs.average().plot_joint(picks='eeg', times=[0.1, 0.2, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if I need more control? - matplotlib alternatives\n",
    "\n",
    "If you feel you need more specific control over your plots, it's easy to get the data into a usable format for plotting with matplotlib. You can export both the raw and epoched data using the `get_data()` function, which will allow you to save your data as a numpy array `[ntrials x nchannels x ntimepoints]`.\n",
    "\n",
    "Then, you can do whatever you want with the data! Throw it into matplotlib, use seaborn, or whatever your heart desires!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'eeg':\n",
    "    picks = mne.pick_channels(raw.ch_names, include=['Fz','FCz','Cz','CPz','Pz'])\n",
    "elif data_type == 'ecog':\n",
    "    picks = mne.pick_channels(raw.ch_names, include=['RPPST9','RPPST10','RPPST11'])\n",
    "    \n",
    "f_data = f_epochs.get_data(picks=picks)\n",
    "m_data = m_epochs.get_data(picks=picks)\n",
    "times = f_epochs.times\n",
    "\n",
    "print(f_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot evoked data with errorbars \n",
    "\n",
    "We can recreate some similar plots to those in MNE-python with some of the matplotlib functions. Here we'll create something similar to what was plotted in `plot_compare_evokeds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errorbar(x, ydata, label=None, axlines=True, alpha=0.5, **kwargs):\n",
    "    '''\n",
    "    Plot the mean +/- standard error of ydata.\n",
    "    Inputs:\n",
    "        x : vector of x values\n",
    "        ydata : matrix of your data (this will be averaged along the 0th dimension)\n",
    "        label : A string containing the label for this plot\n",
    "        axlines : [bool], whether to draw the horizontal and vertical axes\n",
    "        alpha: opacity of the standard error area\n",
    "    '''\n",
    "    ymean = ydata.mean(0)\n",
    "    ystderr = ydata.std(0)/np.sqrt(ydata.shape[0])\n",
    "    plt.plot(x, ydata.mean(0), label=label, **kwargs)\n",
    "    plt.fill_between(x, ymean+ystderr, ymean-ystderr, alpha=alpha, **kwargs)\n",
    "    if axlines:\n",
    "        plt.axvline(0, color='k', linestyle='--')\n",
    "        plt.axhline(0, color='k', linestyle='--')\n",
    "    plt.gca().set_xlim([x.min(), x.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_errorbar(times, f_data.mean(0), label='female')\n",
    "plot_errorbar(times, m_data.mean(0), label='male')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Z-scored high gamma')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECoG Exercise:\n",
    "\n",
    "1. If you wanted to look at each ECoG electrode individually to find which ones have responses to the speech data, how would you do this?\n",
    "2. Can you plot the comparison between \"f\" and \"m\" trials for each electrode as a subplot (try using `plt.subplot()` from `matplotlib`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data for f trials\n",
    "\n",
    "# Get the data for m trials\n",
    "\n",
    "# Loop through each channel, and create a set of subplots for each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hooray, the End!\n",
    "\n",
    "You did it! Go forth and use MNE-python in your own projects, or even contribute to the code! ðŸ§ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (mne)",
   "language": "python",
   "name": "mne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
