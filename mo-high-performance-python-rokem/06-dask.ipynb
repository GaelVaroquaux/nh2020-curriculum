{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel processing with Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dask](http://dask.pydata.org/) takes yet another approach to speeding up\n",
    "Python computations. One of the main limitations of Python is that in\n",
    "most cases, a single Python interpreter can only access a single thread\n",
    "of computation at a time . This is because of the so-called Global\n",
    "Interpreter Lock (or\n",
    "[GIL](https://docs.python.org/3/glossary.html#term-global-interpreter-lock)).\n",
    "\n",
    "And while there is a\n",
    "[multiprocessing module](https://docs.python.org/3/library/multiprocessing.html)\n",
    "in the Python standard library, it's use is cumbersome and often requires complicated\n",
    "decisions. Dask simplifies this substantially, by making the code simpler, and\n",
    "by making these decisions for you.\n",
    "\n",
    "\n",
    "### Dask delayed computation:\n",
    "\n",
    "Let's look at a simple example. The following are some very fast and simple \n",
    "calculations, and we add some `sleep` into them, to simulate a compute-intensive\n",
    "task that takes some time to complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def inc(x):\n",
    "    time.sleep(1)\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    time.sleep(1)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the calculation in the following cell. How long would it take to execute this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = inc(1)\n",
    "x2 = inc(2)\n",
    "z = add(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that while `z` depends on both `x1` and `x2`, there is no\n",
    "dependency between `x1` and `x2`. In principle, we could compute both of\n",
    "them in parallel, but Python doesn't do that out of the box.\n",
    "\n",
    "One way to convince Python to parallelize these is by telling Dask in\n",
    "advance about the dependencies between different variables, and letting\n",
    "it infer how to distribute the computations across threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "\n",
    "x1 = delayed(inc)(1)\n",
    "x2 = delayed(inc)(2)\n",
    "z = delayed(add)(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `delayed` function (a decorator!) tells Python not to perform\n",
    "the computation until we're done setting up all the data dependencies.\n",
    "Once we're ready to go we can compute one or more of the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much time did this take? Why?\n",
    "\n",
    "Dask computes a task graph for this computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this graph is computed, Dask can see that the two variables do not\n",
    "depend on each other, and they can be executed in parallel. So, a\n",
    "computation that would take 2 seconds serially is immediately sped up\n",
    "n-fold (with n being the number of independent variables, here 2).\n",
    "\n",
    "\n",
    "Dask has implementations of several commonly-used pythonic data-structures. In\n",
    "particular, it implements a data structure that resembles the Numpy Array object\n",
    "and another data structure that resembles the Pandas DataFrame. This lets us do\n",
    "slightly more interesting things and leverage our knowledge of these tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do something slightly more interesting (and neuro-related):\n",
    "\n",
    "Let's say that we'd like to compute the tsnr over several runs of\n",
    "fMRI data, for example, using the open-fMRI dataset ds000114:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "fnames = glob(op.join(op.expanduser('~'), 'data/openneuro/ds000114/sub-01/ses-test/func/*.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list with 5 different file-names, for the different runs during\n",
    "this session.\n",
    "\n",
    "One way to calculate the tsnr across is to loop over the\n",
    "files, read in the data for each one of them, concatenate the data and then\n",
    "compute the tsnr from the concatenated series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for fname in fnames:\n",
    "    data.append(nib.load(fname).get_fdata())\n",
    "\n",
    "data = np.concatenate(data, -1)\n",
    "tsnr = data.mean(-1) / data.std(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Lazy loading in Nibabel\n",
    "> Nibabel uses \"lazy loading\". That means that data are not read from file\n",
    "> until when the nibabel `load` function is called on a file-name. Instead,\n",
    "> Nibabel waits until we ask for the data, using the `get_data` method of\n",
    "> The `Nifti1Image` class to read the data from file.\n",
    "\n",
    "When we do that, most of the time is spent on reading the data from file.\n",
    "As you can probably reason yourself, the individual items in the data\n",
    "list have no dependency on each other, so they could be calculated in\n",
    "parallel.\n",
    "\n",
    "Because of nibabel's lazy-loading, we can instruct it to wait with the\n",
    "call to `get_data`. We create a delayed function that we call\n",
    "`delayed_get_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_get_data = delayed(nib.Nifti1Image.get_fdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use this function to create a list of items and delay each one\n",
    "of the computations on this list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for fname in fnames:\n",
    "    data.append(delayed_get_data(nib.load(fname)))\n",
    "\n",
    "data = delayed(np.concatenate)(data, -1)\n",
    "tsnr = delayed(data.mean)(-1) / delayed(data.std)(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask figures that out for you as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsnr.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed computing tsnr this way can give you an approximately 4-fold\n",
    "speedup. This is because Dask allows the Python process to read several\n",
    "of the files in parallel, and that is the performance bottle-neck here.\n",
    "\n",
    "### Dask arrays\n",
    "\n",
    "This is already quite useful, but wouldn't you rather just tell dask that\n",
    "you are going to create some data and to treat it all as delayed until\n",
    "you are ready to compute the tsnr?\n",
    "\n",
    "This idea is implemented in the dask array interface. The idea here is that\n",
    "you create something that provides all of the interfaces of a numpy array, but\n",
    "all the computations are treated as delayed.\n",
    "\n",
    "This is what it would look like for the tsnr example. Instead of\n",
    "appending delayed calls to `get_data` into the array, we create a series\n",
    "of dask arrays, with `delayed_get_data`. We do need to know both the shape\n",
    "and data type of the arrays that will eventually be read, but"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "delayed_arrays = []\n",
    "for fname in fnames:\n",
    "    img = nib.load(fname)\n",
    "    delayed_arrays.append(da.from_delayed(delayed_get_data(img),\n",
    "                          img.shape,\n",
    "                          img.get_data_dtype()))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we examine these variables, we'll see something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are notional arrays, that have not been materialized yet. The data\n",
    "has not been read from memory yet, although dask already knows where it\n",
    "would put them when they should be read.\n",
    "\n",
    "We can use the `dask.array.concatenate` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = da.concatenate(delayed_arrays, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can then use methods of the `dask.array` object to complete the\n",
    "computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsnr = arr.mean(-1) / arr.std(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks exactly like the code we used for the numpy array!\n",
    "\n",
    "Given more insight into what you want to do, dask is able to construct an\n",
    "even more sophisticated task graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsnr.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks really complicated, but notice that because dask has even more\n",
    "insight into what we are trying to do, it can delay some things until\n",
    "after aggregation. For example, the square root computation of the\n",
    "standard deviation can be done once at the end, instead of on each array\n",
    "separately.\n",
    "\n",
    "And this leads to an approximately additional 2-fold speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "tsnr.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main things to notice about the dask array is that because the\n",
    "data is not read into memory it can represent very large datasets, and\n",
    "schedule operations over these large datasets in a manner that makes the code\n",
    "seem as though all the data is in memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
